{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b621a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import DistilBertForSequenceClassification, file_utils, Pipeline, AutoTokenizer, pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from convokit import Corpus, download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5691b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./results/models/best\"\n",
    "model_describ = \"distilbert-base-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c773ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model\n",
    "model2 = DistilBertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_describ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1564413",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    \"admiration\",\n",
    "    \"amusement\",\n",
    "    \"anger\",\n",
    "    \"annoyance\",\n",
    "    \"approval\",\n",
    "    \"caring\",\n",
    "    \"confusion\",\n",
    "    \"curiosity\",\n",
    "    \"desire\",\n",
    "    \"disappointment\",\n",
    "    \"disapproval\",\n",
    "    \"disgust\",\n",
    "    \"embarrassment\",\n",
    "    \"excitement\",\n",
    "    \"fear\",\n",
    "    \"gratitude\",\n",
    "    \"grief\",\n",
    "    \"joy\",\n",
    "    \"love\",\n",
    "    \"nervousness\",\n",
    "    \"optimism\",\n",
    "    \"pride\",\n",
    "    \"realization\",\n",
    "    \"relief\",\n",
    "    \"remorse\",\n",
    "    \"sadness\",\n",
    "    \"surprise\",\n",
    "    \"neutral\"\n",
    "  ]\n",
    "id2label = {i:label for i,label in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27c1cacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\daten\\studium\\master\\exercise\\semester2\\nlp\\nlp\\lib\\site-packages\\torchaudio\\backend\\utils.py:67: UserWarning: No audio backend is available.\n",
      "  warnings.warn('No audio backend is available.')\n"
     ]
    }
   ],
   "source": [
    "from source.classification_utils import MultiLabelTextClassification\n",
    "\n",
    "def analyze_result(result, threshold = 0.5):\n",
    "    \"\"\"Sort the results and throw away all labels with prediction under threshold\"\"\"\n",
    "    output = []\n",
    "    for sample in result:\n",
    "        sample = np.array(sample)\n",
    "        scores = np.array([label['score'] for label in sample])\n",
    "        predicted_samples = np.argwhere(scores > threshold).reshape(-1)\n",
    "        output.append(sorted(sample[predicted_samples], key = lambda item: item['score'], reverse=True))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f4d020",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = {\n",
    "    \"return_all_scores\":True,\n",
    "    \"device\":0    \n",
    "}\n",
    "inference_pipeline = MultiLabelTextClassification(model=model2, tokenizer=tokenizer, **pipeline_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ab8330",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_classifier = \"typeform/distilbert-base-uncased-mnli\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24c06c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_pipeline = pipeline(\"zero-shot-classification\", device=0, model=zero_shot_classifier, tokenizer = zero_shot_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d731f8d5",
   "metadata": {},
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbf5b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data/friends-final-raw.txt\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d80c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(filename=download(\"tennis-corpus\"))\n",
    "utterances = list(corpus.iter_utterances())\n",
    "texts = [t.text for t in utterances]\n",
    "speakers = [t.get_speaker().id for t in utterances]\n",
    "dataset = pd.DataFrame(zip(texts, speakers), columns=['line', 'person']) # todo: change name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7328ebc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['person'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaca29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into sentences\n",
    "dataset[\"line\"] = dataset[\"line\"].str.split(r'[.!?]+\\s')\n",
    "person_counts = dataset[\"person\"].value_counts()\n",
    "main_characters = person_counts[person_counts > 1000].reset_index()[\"index\"]\n",
    "print(main_characters)\n",
    "\n",
    "dataset = dataset[dataset[\"person\"].isin(main_characters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2075eccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_emotions = {}\n",
    "for p in main_characters:\n",
    "    predicted_emotions[p] = list()\n",
    "\n",
    "for row in tqdm(dataset.itertuples(), total=len(dataset)):\n",
    "    #prediction = zero_shot_pipeline(row.line, labels, multi_label=True)\n",
    "    #if len(row.line) == 1:\n",
    "    #    prediction = [prediction]\n",
    "    #prediction = [[{'label' : label, 'score': value} for label, value in zip(sentence['labels'], sentence['scores'])] for sentence in prediction]\n",
    "    #result = analyze_result(prediction, .8)\n",
    "    prediction = inference_pipeline(row.line)\n",
    "    result = analyze_result(prediction, .2)\n",
    "    result = [(pred['label'], pred['score']) for pred in result[0]] \n",
    "    predicted_emotions[row.person].append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0c6493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeb7e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/friends-classification.pickle', 'wb') as f:\n",
    "    pickle.dump(predicted_emotions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbee3da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_emotions = pickle.load(open('data/tennis-classification.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878500aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_emotions_per_person = {}\n",
    "for p in main_characters:\n",
    "    total_emotions_per_person[p] = {}\n",
    "    for l in labels:\n",
    "        total_emotions_per_person[p][l] = 0\n",
    "\n",
    "for person, sentences in predicted_emotions.items():    \n",
    "    for s in sentences:\n",
    "        for e in s:\n",
    "            total_emotions_per_person[person][e[0]] += (e[1]/ len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d473a5",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db09844b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for person, emotions in total_emotions_per_person.items():\n",
    "    plt.title(person)\n",
    "    plt.ylim((0,0.1))\n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.bar(range(0, len(labels)), emotions.values(), tick_label=labels)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6074cd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"person\", \"emotion\", \"value\"])\n",
    "\n",
    "for person, emotions in total_emotions_per_person.items():\n",
    "    for emotion, value in emotions.items():\n",
    "        df.loc[len(df)] = [person,emotion,value]\n",
    "        \n",
    "#df = df[df[\"emotion\"] != \"neutral\"]\n",
    "sns.set(rc={'figure.figsize':(30,8)})\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "chart = sns.barplot(x=\"emotion\", y=\"value\", hue=\"person\", data=df)\n",
    "chart.set_xticklabels(chart.get_xticklabels(), rotation=90)\n",
    "chart.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b778f9e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
